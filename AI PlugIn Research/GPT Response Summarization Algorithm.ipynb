{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCe3OcuvF1iF"
   },
   "source": [
    "# Framework Configuration\n",
    "Load Libraries - Mount Google Drive - Load GPT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5367,
     "status": "ok",
     "timestamp": 1727386227947,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "m0IFrjVXDPTD"
   },
   "outputs": [],
   "source": [
    "#@title Load Libraries\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "import locale\n",
    "\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy.special import rel_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5700,
     "status": "ok",
     "timestamp": 1727387005048,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "8NX9TLNdgrPS",
    "outputId": "837e0a7a-ec82-45c2-9bd8-52f0c35eff26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Connor\n",
      "[nltk_data]     Nesbit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Connor\n",
      "[nltk_data]     Nesbit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#@title Stop/Stem Downloads\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "if input(\"Do you want to run the NLTK Downloads? (y/n): \") == \"y\":\n",
    "  nltk.download('punkt')\n",
    "  nltk.download('stopwords')\n",
    "\n",
    "if input(\"Do you want to run Stop/Stem Words Example? (y/n): \") == \"y\":\n",
    "  stemmer = PorterStemmer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  sen = \"The dancers from Denmark dance a traditional dance\"\n",
    "  sen_list = sen.split()\n",
    "  print(sen_list)\n",
    "\n",
    "  no_stop_list = [w for w in sen_list if not w in stop_words]\n",
    "  print(no_stop_list)\n",
    "\n",
    "  stemmed_list = [stemmer.stem(w) for w in no_stop_list]\n",
    "  print(stemmed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16054,
     "status": "ok",
     "timestamp": 1727387024131,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "_b7AljbHFZZc",
    "outputId": "9ba8b8a0-9f15-4b86-ce6d-215104253c2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14492,
     "status": "ok",
     "timestamp": 1727387629660,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "QPXV84NBFmeD",
    "outputId": "5dd5fc69-f0b7-43eb-d02d-88bdc86415f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run this program, you must add a shortcut to the AI PlugIn Research folder for your personal Google Drive to access through the shared Google Drive.\n",
      "Have you added that shortcut? (y/n): 3.5\n",
      "You must add a shortcut to the AI PlugIn Research folder to access through the shared Google Drive.\n",
      "Have you added that shortcut? (y/n): y\n",
      "Which GPT version do you want to run the summarization on? (3.5/4.0): 3.5\n",
      "GPT Data Loaded in a DataFrame.\n"
     ]
    }
   ],
   "source": [
    "#@title Load GPT Data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"To run this program, you must add a shortcut to the AI PlugIn Research folder for your personal Google Drive to access through the shared Google Drive.\")\n",
    "while True:\n",
    "  added_shortcut = input(\"Have you added that shortcut? (y/n): \").lower() == \"y\"\n",
    "  if added_shortcut:\n",
    "    break\n",
    "  print(\"You must add a shortcut to the AI PlugIn Research folder to access through the shared Google Drive.\")\n",
    "\n",
    "version = input(\"Which GPT version do you want to run the summarization on? (3.5/4.0): \")\n",
    "if version == \"3.5\":\n",
    "  drive_path = '/content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Multiple_Responses_GPT_Conversations.xlsx'\n",
    "  df = pd.read_excel(drive_path)\n",
    "  print(\"GPT Data Loaded in a DataFrame.\")\n",
    "elif version == \"4.0\":\n",
    "  drive_path = '/content/drive/MyDrive/AI PlugIn Research/GPT 4.0 Data/Multiple_Responses_GPT_Conversations.xlsx'\n",
    "  df = pd.read_excel(drive_path)\n",
    "  print(\"GPT Data Loaded in a DataFrame.\")\n",
    "else:\n",
    "  print(\"Invalid GPT version. Please enter '3.5' or '4.0'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaFjoFzAGfnu"
   },
   "source": [
    "# Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3997,
     "status": "ok",
     "timestamp": 1727387049133,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "YzDKXY_aH4Yy",
    "outputId": "b5df34fa-d3b1-4264-c9db-736aed0209c4"
   },
   "outputs": [],
   "source": [
    "#@title KL Divergence Formula\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.special import rel_entr\n",
    "\n",
    "# Formula for P's divergence from Q: KL(P || Q) = â€“ sum x in X P(x) * log(Q(x) / P(x))\n",
    "# If we are attempting to approximate an unknown probability distribution, then the target probability distribution from data is P, and Q is our approximation of the distribution.\n",
    "\n",
    "def kl_archive_divergence (arc_dict, arc_word_num, sen_dict, sen_word_num):\n",
    "  if sen_word_num == 0:\n",
    "      return 1000\n",
    "\n",
    "  total_sum = 0\n",
    "  for word in sen_dict:\n",
    "      a = arc_dict[word] / arc_word_num\n",
    "      b = sen_dict[word] / sen_word_num\n",
    "      val = a * np.log(a / b)\n",
    "      total_sum += val\n",
    "\n",
    "  total_sum = total_sum / sen_word_num\n",
    "  return total_sum\n",
    "\n",
    "def kl_archive_divergence_op(arc_dict, arc_word_num, sen_dict, sen_word_num):\n",
    "  if sen_word_num == 0:\n",
    "      return 1000\n",
    "\n",
    "  arc_probs = np.array([arc_dict.get(word, 0) / arc_word_num for word in sen_dict])\n",
    "  sen_probs = np.array([sen_dict[word] / sen_word_num for word in sen_dict])\n",
    "\n",
    "  kl_values = rel_entr(arc_probs, sen_probs)\n",
    "  total_kl_divergence = np.sum(kl_values) / sen_word_num\n",
    "\n",
    "  return total_kl_divergence\n",
    "\n",
    "if input(\"Do you want to run NLP KL-D example? (y/n): \") == \"y\":\n",
    "\n",
    "  np.random.seed(0)\n",
    "  num_words = 10000\n",
    "  arc_words = [f'word{i}' for i in range(num_words)]\n",
    "  sen_words = [f'word{i}' for i in range(num_words)]\n",
    "\n",
    "  arc_frequencies = np.random.randint(1, 100, size=num_words)\n",
    "  sen_frequencies = np.random.randint(1, 100, size=num_words)\n",
    "\n",
    "  arc_dict = dict(zip(arc_words, arc_frequencies))\n",
    "  sen_dict = dict(zip(sen_words, sen_frequencies))\n",
    "\n",
    "  arc_word_num = sum(arc_frequencies)\n",
    "  sen_word_num = sum(sen_frequencies)\n",
    "\n",
    "  start_time = time.time()\n",
    "  kl_div = kl_archive_divergence(arc_dict, arc_word_num, sen_dict, sen_word_num)\n",
    "  end_time = time.time()\n",
    "  print(\"KL Divergence Time:\", end_time - start_time)\n",
    "\n",
    "  start_time_op = time.time()\n",
    "  kl_div_op = kl_archive_divergence_op(arc_dict, arc_word_num, sen_dict, sen_word_num)\n",
    "  end_time_op = time.time()\n",
    "  print(\"Optimized KL Divergence Time:\", end_time_op - start_time_op)\n",
    "\n",
    "  print(\"KL Divergence:\", kl_div)\n",
    "  print(\"Optimized KL Divergence:\", kl_div_op)\n",
    "\n",
    "if input(\"Do you want to run Probability Distribution KL Divergence Example? (y/n): \") == \"y\":\n",
    "\n",
    "  def kl_ex(p, q):\n",
    "    return sum(p[i] * np.log(p[i] / q[i]) for i in range(len(p)))\n",
    "\n",
    "  p = [0.10, 0.15, 0.05, 0.20, 0.25, 0.10, 0.05, 0.10]\n",
    "  q = [0.15, 0.10, 0.20, 0.10, 0.10, 0.05, 0.20, 0.10]\n",
    "  print(kl_ex(p, q))\n",
    "  print(np.sum(rel_entr(p, q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1727387056270,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "PWCwAOfyFJ6Z",
    "outputId": "a1a83d65-a2cf-4033-991d-fbf00852e5a2"
   },
   "outputs": [],
   "source": [
    "#@title Sentence Class\n",
    "\n",
    "class Sentence:\n",
    "  def __init__(self, sen, id):\n",
    "    self.og_sen = sen\n",
    "    self.og_num_words = 0\n",
    "    self.filt_sen = \"\"\n",
    "    self.filt_num_words = 0\n",
    "    self.word_freq_dict = {}\n",
    "    self.in_summary = False\n",
    "    self.id = id\n",
    "    if self.og_sen[-1] not in string.punctuation:\n",
    "        self.og_sen = self.og_sen + \".\"\n",
    "\n",
    "  def get_sen(self):\n",
    "    return self.og_sen\n",
    "\n",
    "  def get_og_num_words(self):\n",
    "    return self.og_num_words\n",
    "\n",
    "  def get_filt_num_words(self):\n",
    "    return self.filt_num_words\n",
    "\n",
    "  def get_dict(self):\n",
    "    return self.word_freq_dict\n",
    "\n",
    "  def add_to_summary(self):\n",
    "    self.in_summary = True\n",
    "\n",
    "  def is_in_summary(self):\n",
    "    return self.in_summary\n",
    "\n",
    "  def get_id(self):\n",
    "    return self.id\n",
    "\n",
    "  def filter(self):\n",
    "    self.filt_sen = self.og_sen.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    word_list = self.filt_sen.split()\n",
    "    self.og_num_words = len(word_list)\n",
    "    filt_word_list = [w for w in word_list if w not in stop_words]\n",
    "    self.filt_num_words = len(filt_word_list)\n",
    "\n",
    "    self.word_freq_dict = {}\n",
    "    for word in filt_word_list:\n",
    "      stem_word = stemmer.stem(word)\n",
    "      self.word_freq_dict[stem_word] = self.word_freq_dict.get(stem_word, 0) + 1\n",
    "\n",
    "    return self.word_freq_dict\n",
    "\n",
    "  def __repr__(self):\n",
    "    return (f\"Sentence(id={self.id!r}, og_sen={self.og_sen!r}, \"\n",
    "            f\"og_num_words={self.og_num_words!r}, filt_sen={self.filt_sen!r}, \"\n",
    "            f\"filt_num_words={self.filt_num_words!r}, word_freq_dict={self.word_freq_dict!r}, \"\n",
    "            f\"in_summary={self.in_summary!r})\")\n",
    "\n",
    "if input(\"Do you want to run Sentence Example? (y/n): \") == \"y\":\n",
    "\n",
    "  sentence = \"His name was Jack Jack Black which was crazy since his mother was named Jackie Jack Black\"\n",
    "  id = 1\n",
    "\n",
    "  sentence_data = Sentence(sentence, id)\n",
    "  filtered_dict = sentence_data.filter()\n",
    "\n",
    "  print(\"Original Sentence:\", sentence_data.get_sen())\n",
    "  print(\"Original Word Count:\", sentence_data.get_og_num_words())\n",
    "  print(\"Filtered Word Count:\", sentence_data.get_filt_num_words())\n",
    "  print(\"Stemmed Dictionary:\", sentence_data.get_dict())\n",
    "  print(\"Is in Summary:\", sentence_data.is_in_summary())\n",
    "  print(\"ID:\", sentence_data.get_id())\n",
    "\n",
    "  sentence_data.add_to_summary()\n",
    "  print(\"Is in Summary (after adding):\", sentence_data.is_in_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1727387062870,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "XNlo5gTmYz1Q"
   },
   "outputs": [],
   "source": [
    "#@title Archive Class\n",
    "\n",
    "class Archive:  # Gets reviews, parses by sentence, gets KL scores, builds summary. Has 3 levels of affecting redundancy\n",
    "  def __init__(self, responses, redun_level, lim_type):\n",
    "    if responses is not None:\n",
    "        self.df = responses\n",
    "    self.sen_list = []\n",
    "    self.total_words = 0\n",
    "    self.min_words = 20\n",
    "    self.full_dictionary = {}\n",
    "    self.num_filter_words = 0\n",
    "    self.kl_list = []\n",
    "    self.summary = []\n",
    "    self.summary_word_num = 0\n",
    "    self.summary_limit = 250  # UPDATE SUMMARY LENGTH HERE\n",
    "    self.kl_counter = 0\n",
    "    self.min_sen_length = 5\n",
    "    self.max_sen_length = 29\n",
    "    self.redun_level = redun_level\n",
    "    self.doc = None\n",
    "    self.rev_count = 0\n",
    "    self.lim_type = lim_type\n",
    "    self.has_positive = False\n",
    "\n",
    "  def run_summarization(self):\n",
    "    self.load_sentences()\n",
    "    if self.check_summarization():\n",
    "      self.kl_divergence()\n",
    "      self.build_summary()\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  def check_summarization(self):\n",
    "    if self.total_words > self.min_words:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "  def set_doc(self, doc):\n",
    "    self.doc = doc\n",
    "\n",
    "  def set_summary_limit(self, num_responses):\n",
    "    if self.lim_type == \"250\":\n",
    "        self.summary_limit = 250\n",
    "    if self.lim_type == \"percent\":\n",
    "        self.summary_limit = int(len(self.sen_list) * .15)\n",
    "    if self.lim_type == \"rev_count\":\n",
    "        self.summary_limit = int(num_responses / 5) * 25\n",
    "\n",
    "  def set_summary_limit_doc(self):\n",
    "    self.summary_limit = int(self.total_words * .8)  # *1 for full match. * .8 to trim size\n",
    "\n",
    "  def get_summary_word_num(self):\n",
    "    return self.summary_word_num\n",
    "\n",
    "  def get_full_dictionary(self):\n",
    "    return self.full_dictionary\n",
    "\n",
    "  def get_word_counts(self):\n",
    "    return self.total_words, self.num_filter_words\n",
    "\n",
    "  def get_sen_list(self):\n",
    "    return self.sen_list\n",
    "\n",
    "  def get_lim_type(self):\n",
    "    return self.lim_type\n",
    "\n",
    "  def get_has_positive(self):\n",
    "    return self.has_positive\n",
    "\n",
    "  def kl_divergence(self):  # Calculates each sentence's KL_score, appends to kl_list in respective order\n",
    "    self.kl_list.clear()\n",
    "    for i in range(len(self.sen_list)):\n",
    "        if not self.sen_list[i].is_in_summary():\n",
    "            self.kl_list.append(kl_archive_divergence_op(\n",
    "                self.full_dictionary,\n",
    "                self.num_filter_words,\n",
    "                self.sen_list[i].word_freq_dict,\n",
    "                self.sen_list[i].filt_num_words))\n",
    "            if 0 < self.kl_list[-1] < 100:\n",
    "                self.has_positive = True\n",
    "        else:\n",
    "            self.kl_list.append(100)  # 100 when aiming for min KL (our default), -100 when aiming for max KL\n",
    "    self.kl_counter += 1\n",
    "\n",
    "  def get_kl(self):\n",
    "    return self.kl_list\n",
    "\n",
    "  def remove_redundancy(self, index):  # After sentence is added to summary, remove its filtered word occurrences from the archive dictionary\n",
    "    self.sen_list[index].add_to_summary()  # Flags sentence as used\n",
    "    sen_dict = self.sen_list[index].get_dict()\n",
    "    for word in sen_dict:  # Nothing happens if redun_level = 0\n",
    "        if self.redun_level == 2:  # New idea, bigger redundancy removal by dividing the remaining frequency by the used sentence frequency 10 / 3 = 3.3333\n",
    "            self.full_dictionary[word] = self.full_dictionary[word] / sen_dict[word]\n",
    "            self.num_filter_words -= sen_dict[word]\n",
    "        if self.redun_level == 1:  # OG idea, just reduces the archive frequency by the used sentence frequency 10 - 3 = 7\n",
    "            self.full_dictionary[word] -= sen_dict[word]\n",
    "            self.num_filter_words -= sen_dict[word]\n",
    "\n",
    "  def print_sen_and_kl(self):\n",
    "    for i in range(len(self.sen_list)):\n",
    "        print(self.kl_list[i], \"\\t\", self.sen_list[i].get_sen())\n",
    "\n",
    "  def build_summary(self):\n",
    "    if self.lim_type == \"percent\":\n",
    "        measure = \"sentences\"\n",
    "    else:\n",
    "        measure = \"words\"\n",
    "    print(\"Building Summary. \\tlimitType =\", self.lim_type, \" summary limit = \", self.summary_limit, measure, \"\\n\")\n",
    "    counter = 0\n",
    "    while counter < self.summary_limit:\n",
    "        min_val = min(self.kl_list)\n",
    "        max_index = self.kl_list.index(min_val)\n",
    "        if min_val == 100:  # Breaks while loop if we're out of sentences\n",
    "            break\n",
    "        if self.sen_list[max_index].get_og_num_words() >= self.min_sen_length \\\n",
    "                and self.sen_list[max_index].get_og_num_words() <= self.max_sen_length:  # Only accepts 5 <= Sentence Length <= 29\n",
    "            if len(self.summary) > 0 and self.sen_list[max_index].get_sen() == self.summary[-1]:  # Ignore duplicate sentences\n",
    "                dummy = 0\n",
    "            else:\n",
    "                self.summary.append(self.sen_list[max_index].get_sen())  # Add sentence to summary\n",
    "                self.summary_word_num += self.sen_list[max_index].get_og_num_words()  # Add to total word count\n",
    "        self.remove_redundancy(max_index)\n",
    "        self.kl_divergence()\n",
    "        if self.lim_type == \"percent\":\n",
    "            counter = len(self.summary)\n",
    "        else:\n",
    "            counter = self.summary_word_num\n",
    "\n",
    "  def print_summary_as_paragraph(self):\n",
    "    return ' '.join(self.summary)\n",
    "\n",
    "  def print_summary_by_lines(self):\n",
    "    print(\"Here is the summary by lines: , \\t \", self.summary_word_num, \" words\")\n",
    "    print()\n",
    "    for sen in self.summary:\n",
    "        print(sen)\n",
    "    return self.summary\n",
    "\n",
    "  def get_summary(self):\n",
    "    return self.summary\n",
    "\n",
    "  def load_sentences(self):\n",
    "    self.total_words = 0\n",
    "    rev_counter = 0\n",
    "    for i in self.df.index:\n",
    "        rev = self.df.at[i, \"answer_text\"]  # Parses out review info\n",
    "        temp_list = nltk.tokenize.sent_tokenize(rev)  # Splits review into sentences\n",
    "        for j in range(len(temp_list)):\n",
    "            sen = Sentence(temp_list[j], rev_counter)  # Creates Sentence\n",
    "            self.sen_list.append(sen)  # Adds Sentence to list\n",
    "            self.total_words += len(temp_list[j].split())\n",
    "            sen_dict = self.sen_list[-1].filter()  # Returns Sentence's filtered dictionary\n",
    "\n",
    "            for word in sen_dict:  # Add sentence filter dictionary to archive filter dictionary\n",
    "                if word in self.full_dictionary:\n",
    "                    self.full_dictionary[word] += sen_dict[word]\n",
    "                else:\n",
    "                    self.full_dictionary[word] = sen_dict[word]\n",
    "                self.num_filter_words += sen_dict[word]\n",
    "        rev_counter += 1\n",
    "    self.set_summary_limit(rev_counter)\n",
    "    self.rev_count = rev_counter\n",
    "\n",
    "  def load_sentences_doc(self, doc):  # Input is just one line/paragraph.\n",
    "    self.total_words = 0\n",
    "    rev_counter = 0\n",
    "    self.doc = doc\n",
    "    temp_list = nltk.tokenize.sent_tokenize(self.doc)  # Splits review into sentences\n",
    "    for j in range(len(temp_list)):\n",
    "        sen = Sentence(temp_list[j], rev_counter)  # Creates Sentence\n",
    "        self.sen_list.append(sen)  # Adds Sentence to list\n",
    "        self.total_words += len(temp_list[j].split())\n",
    "        sen_dict = self.sen_list[-1].filter()  # Returns Sentence's filtered dictionary\n",
    "        for word in sen_dict:  # Add sentence filter dictionary to archive filter dictionary\n",
    "            if word in self.full_dictionary:\n",
    "                self.full_dictionary[word] += sen_dict[word]\n",
    "            else:\n",
    "                self.full_dictionary[word] = sen_dict[word]\n",
    "            self.num_filter_words += sen_dict[word]\n",
    "    rev_counter += 1\n",
    "    self.set_summary_limit_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1727387070862,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "kdGA00xFV0xu"
   },
   "outputs": [],
   "source": [
    "#@title Bold Formatting Function\n",
    "\n",
    "def populate_bold_text(text):\n",
    "    text = text.replace('**', '\\033[1m', 1)\n",
    "    text = text.replace('**', '\\033[0m', 1)\n",
    "\n",
    "    while '**' in text:\n",
    "        text = text.replace('**', '\\033[1m', 1)\n",
    "        text = text.replace('**', '\\033[0m', 1)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rWS61DZhmQU"
   },
   "source": [
    "# Summarization of GPT Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29274,
     "status": "ok",
     "timestamp": 1727387687008,
     "user": {
      "displayName": "Connor Nesbit",
      "userId": "15816288068957908604"
     },
     "user_tz": 360
    },
    "id": "5bg2M60NIDNi",
    "outputId": "4770d7ee-c127-448e-d964-8eadcb05f9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want a summary for each conversation or for each response? (conv/res)res\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_1.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  9  words\n",
      "\n",
      "So, the time and space complexity both remain O(n).\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_2.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  8  words\n",
      "\n",
      "This is because BFS visits each node once.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_3.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  17  words\n",
      "\n",
      "It helps in avoiding duplicate combinations.\n",
      "- `sum_path`: This parameter keeps track of the current combination being explored.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_4.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  20  words\n",
      "\n",
      "Therefore, the time complexity is O(2^n) in the worst case.\n",
      "Therefore, the space complexity is O(2^n) in the worst case.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_5.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_6.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  5  words\n",
      "\n",
      "Thank you for your patience!\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_7.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  17  words\n",
      "\n",
      "This also can be exponential in the worst case, \\(O(2^m)\\), where \\(m\\) is the number of candidates.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_8.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_9.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  36  words\n",
      "\n",
      "One chromosome of each pair is inherited from each parent.\n",
      "Different alleles can result in variations in the expressed trait.\n",
      "An organism is heterozygous for a gene if it has two different alleles for that gene.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_10.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_11.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  5  words\n",
      "\n",
      "Yes, that definition is correct.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_12.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  11  words\n",
      "\n",
      "- **Same Genes**: They carry the same genes in the same order.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_13.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  53  words\n",
      "\n",
      "- **Linked genes** tend to be inherited together because of their physical proximity on the same chromosome.\n",
      "- **Mendel's Law of Independent Assortment** applies to genes on different chromosomes or far apart on the same chromosome.\n",
      "This process can \"unlink\" genes that are located on the same chromosome by physically exchanging segments between homologous chromosomes.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_14.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  20  words\n",
      "\n",
      "- **Heterozygous (Aa)**: The trait is expressed.\n",
      "- **Homozygous Recessive (aa)**: The trait is expressed.\n",
      "- **Homozygous Dominant (AA)**: The trait is expressed.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_15.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  7 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  38  words\n",
      "\n",
      "- Both males and females affected.\n",
      "**More males affected** than females.\n",
      "- More males than females affected.\n",
      "- Affected males often have carrier mothers.\n",
      "- Affected individuals have unaffected parents (carriers).\n",
      "- Disorder appears to skip generations.\n",
      "**Affected individuals** often have unaffected parents.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_16.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  20  words\n",
      "\n",
      "- Daughters will inherit the normal X chromosome from the father (X).\n",
      "**Females** have two X chromosomes, one from each parent.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_17.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  51  words\n",
      "\n",
      "\n",
      "\n",
      "Genes that are located close to each other on the same chromosome are referred to as linked genes.\n",
      "- **Linked genes**: Tend to be inherited together due to their proximity on the same chromosome.\n",
      "- **Mendel's Law of Independent Assortment**: Applies to genes on different chromosomes or far apart on the same chromosome.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_18.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  34  words\n",
      "\n",
      "This reciprocal exchange is called homologous recombination or crossing over.\n",
      "This increases genetic diversity in the offspring.\n",
      "- **Linked Genes**: Genes located close to each other on the same chromosome tend to be inherited together.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_19.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  4 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  55  words\n",
      "\n",
      "This indicates that crossing over occurred and affected the linked genes.\n",
      "This indicates that no crossing over or crossing over that did not affect the linked genes occurred.\n",
      "**Recombinant Chromosomes**: Chromosomes that have undergone crossing over and have new combinations of alleles.\n",
      "It gives an indication of how often crossing over occurs between linked genes.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_20.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  17  words\n",
      "\n",
      "\"The boundaries between dreams and waking life blurred.\"\n",
      "\"Everyday life intertwined with the mystical and the inexplicable.\"\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_21.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  17  words\n",
      "\n",
      "Tai's enigmatic nature and his ability to weave tales contribute to the magical realism of the scene.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_22.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  14  words\n",
      "\n",
      ".â€™ Tai pointed at the mountains.\n",
      "Tai's response is colorful and emphatic:\n",
      "\n",
      "\"'How old?\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_23.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  14  words\n",
      "\n",
      "Similarly, Tai's response to Doctor Aziz's question about his age also showcases magical realism.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_24.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  34  words\n",
      "\n",
      "This theme adds depth to the narrative and underscores the multifaceted nature of human experience.\n",
      "**Acceptance and Belonging**: Characters in the story seek acceptance and a sense of belonging within their communities and families.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_25.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  37  words\n",
      "\n",
      "These multiple voices contribute to the postmodernist emphasis on plurality and diversity.\n",
      "This intertextuality enriches the narrative by connecting it to broader cultural contexts.\n",
      "\"The Perforated Sheet\" by Salman Rushdie exhibits several characteristics of postmodernist literature:\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_26.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_27.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_28.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  25  words\n",
      "\n",
      "This temporal distortion highlights the fluidity of memory and its subjective nature.\n",
      "**Temporal Distortion:** The novel plays with time, especially through the Professor's memory loss.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_29.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_30.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  6 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  123  words\n",
      "\n",
      "\"In the pages of the novel, the characters took on a life of their own, their stories unfolding in ways I had never imagined.\"\n",
      "\"In the end, we were left with only fragments of the life we had known, scattered like ashes on the wind.\"\n",
      "\"Time in the house seemed to bend and warp, leaving us adrift in a sea of fragmented moments.\"\n",
      "\"The novel seemed to take on a life of its own, the characters leading me down unexpected paths, their stories intertwining with my own.\"\n",
      "\"The boundaries between fact and fiction seemed to dissolve, leaving me adrift in a sea of uncertainty.\"\n",
      "\"Each day felt like a separate piece of a puzzle, disconnected from the one before and the one after.\"\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_31.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_32.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  36  words\n",
      "\n",
      "These modernist techniques contribute to the novel's exploration of memory, human connection, and the search for meaning in an uncertain world.\n",
      "\"The Housekeeper and the Professor\" by Yoko Ogawa employs several modernist literary techniques, including:\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_33.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  33  words\n",
      "\n",
      "\"I had forgotten, for a moment, about the strange figure of the professor.\n",
      "- The Housekeeper's stream of consciousness reflects her introspective mood as she reflects on her past while wandering through the garden.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_34.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  38  words\n",
      "\n",
      "I feared what the future held for him, for us.\"\n",
      "His memory lapses were becoming more frequent, more pronounced.\n",
      "It was as if time itself was conspiring against him, stealing away the very essence of who he was.\"\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_35.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  36  words\n",
      "\n",
      "It was my job to piece them together, to make sense of the disjointed puzzle that was his memory.\n",
      "Certainly, here are more examples of modernist literary techniques used in \"The Housekeeper and the Professor\":\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_36.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  4 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  33  words\n",
      "\n",
      "- Reflects a more organized and controlled flow of thoughts.\n",
      "- **Example**: \"Raindrops on the window.\n",
      "- Mimics the spontaneous and nonlinear nature of human consciousness.\n",
      "It was a bittersweet nostalgia, tinged with longing and regret.\"\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_37.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  14  words\n",
      "\n",
      "The novel primarily employs interior monologue rather than a pure stream of consciousness style.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_38.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  15  words\n",
      "\n",
      "Direct dialogue:\n",
      "   \"What do you think, Professor?\"\n",
      "Free indirect dialogue:\n",
      "   What did the Professor think?\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_39.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  19  words\n",
      "\n",
      "This further illustrates her perspective and emotional response to the Professor's discoveries.\n",
      "Here's a breakdown of the quote:\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_40.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  21  words\n",
      "\n",
      "Despite this challenge, the Professor's passion for mathematics remains undiminished, and he often shares his discoveries and insights with the Housekeeper.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_41.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  6  words\n",
      "\n",
      "His excitement was palpable, contagious even.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_42.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_43.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_44.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_45.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  15  words\n",
      "\n",
      "Despite these obstacles, they discover profound connections through their shared passions for baseball and mathematics.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_46.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  8  words\n",
      "\n",
      "Sure, here are some synonyms for \"over\":\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_47.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_48.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_49.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_50.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  37  words\n",
      "\n",
      "This fragmentation disrupts traditional narrative conventions and reflects the modernist tendency to experiment with form and structure.\n",
      "This focus on subjectivity is a hallmark of modernist literature, which often seeks to depict the complexities of human consciousness.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_51.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_52.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  40  words\n",
      "\n",
      "Overall traits of modernism in literature include:\n",
      "\n",
      "1.\n",
      "**Fragmentation:** Modernist works often feature fragmented narratives, non-linear storytelling, and disjointed or discontinuous plot structures.\n",
      "**Experimentation:** Modernist writers often experimented with narrative techniques, structure, and form, breaking away from traditional storytelling methods.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_53.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  3 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  43  words\n",
      "\n",
      "Modernist literature employs a variety of literary techniques to convey its themes, ideas, and aesthetic principles.\n",
      "Some of the key literary techniques associated with modernism include:\n",
      "\n",
      "1.\n",
      "**Fragmentation:** Modernist works frequently feature fragmented narratives, disjointed or non-linear storytelling, and fragmented or disrupted chronology.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_54.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  14  words\n",
      "\n",
      "**Free Indirect Discourse:**\n",
      "   > \"She sighed as she looked out the window, lost in thought.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_55.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  12  words\n",
      "\n",
      "**Free Indirect Discourse:**\n",
      "   > \"She gazed out of the window, lost in reverie.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_56.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_57.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_58.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  22  words\n",
      "\n",
      "This fragmentation mirrors the fragmented nature of urban life and society.\n",
      "This parody serves as a critique of societal norms and values.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_59.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  12  words\n",
      "\n",
      "Certainly, here are examples of fragmentation and metafiction in \"Midaq Alley\":\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_60.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  14  words\n",
      "\n",
      "Certainly, here are some quotes from \"Midaq Alley\" that illustrate fragmentation and metafiction:\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_61.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_62.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_63.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  9  words\n",
      "\n",
      "He loved Hamida, but he knew she deserved better.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_64.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  7  words\n",
      "\n",
      "Was this all life had to offer?\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_65.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  0 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  0  words\n",
      "\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_66.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  17  words\n",
      "\n",
      "Certainly, here are some specific narrative transitions that demonstrate the use of fragmentation in \"Midaq Alley\":\n",
      "\n",
      "1.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_67.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  15  words\n",
      "\n",
      "This technique disrupts the narrative flow and contributes to a sense of disjunction and fragmentation.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_68.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  28  words\n",
      "\n",
      "These temporal shifts fragment the storyline and challenge the reader's sense of coherence.\n",
      "This technique disrupts the narrative flow and contributes to a sense of disjunction and fragmentation.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_69.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  2 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  23  words\n",
      "\n",
      "\"Midaq Alley\" employs fragmentation through various narrative techniques.\n",
      "This technique disrupts the narrative flow and contributes to a sense of disjunction and fragmentation.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_70.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  18  words\n",
      "\n",
      "Each character in the alley has their own version of reality shaped by personal biases, desires, and experiences.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_71.txt\n",
      "\n",
      "\n",
      "~~~Extractor~~~~\n",
      "Building Summary. \tlimitType = percent  summary limit =  1 sentences \n",
      "\n",
      "Here is the summary by lines: , \t  8  words\n",
      "\n",
      "This is because BFS visits each node once.\n",
      "\n",
      "Saved: /content/drive/MyDrive/AI PlugIn Research/GPT 3.5 Data/Response Summaries/summary_id_72.txt\n"
     ]
    }
   ],
   "source": [
    "def save_file(summary, arc, val, version, inp):\n",
    "  if inp == \"conv\":\n",
    "    filename = f\"/content/drive/MyDrive/AI PlugIn Research/GPT {version} Data/Conversation Summaries/summary_id_{val}.txt\"\n",
    "  else:\n",
    "    filename = f\"/content/drive/MyDrive/AI PlugIn Research/GPT {version} Data/Response Summaries/summary_id_{val}.txt\"\n",
    "\n",
    "  with open(filename, 'w') as writefile:\n",
    "    writefile.write(\"Original Response: \\n\")\n",
    "    for item in arc.get_sen_list():\n",
    "      writefile.write(item.get_sen() + \"\\n\")\n",
    "    writefile.write(\"\\nSummary: \\n\")\n",
    "    for j in range(len(summary)):\n",
    "      writefile.write(summary[j] + \"\\n\")\n",
    "  print(\"Saved:\", filename)\n",
    "\n",
    "\n",
    "drive_path = '../cleaned_master_corpus.csv'\n",
    "df = pd.read_csv(drive_path)\n",
    "\n",
    "while True:\n",
    "  inp = input(\"Do you want a summary for each conversation or for each response? (conv/res)\")\n",
    "  if inp == \"conv\":\n",
    "    id = \"conv_id\"\n",
    "    break\n",
    "  elif inp == \"res\":\n",
    "    id = \"res_id\"\n",
    "    break\n",
    "  else:\n",
    "    print(\"Invalid input. Please enter 'conv' or 'res'.\")\n",
    "\n",
    "i = 1\n",
    "for item in range(1, df[f\"{id}\"].max() + 1):\n",
    "  revs = df.loc[df[f\"{id}\"] == item]   #  // gets a set of reviews for a given dataset\n",
    "  no_red = 0\n",
    "  n_grams = 2  #used for the unique-ngram redundancy checker\n",
    "\n",
    "\n",
    "  print(\"\\n\\n~~~Extractor~~~~\")\n",
    "  arc = Archive(revs, no_red, \"percent\");  #use \"250\" , \"percent\" , or \"rev_count\"\n",
    "\n",
    "  if inp == \"conv\":\n",
    "    arc.min_words = 100\n",
    "  else:\n",
    "    arc.min_words = 0\n",
    "\n",
    "  arc.load_sentences()\n",
    "  if arc.total_words > arc.min_words:\n",
    "    arc.kl_divergence()\n",
    "    arc.build_summary()\n",
    "    summary = arc.print_summary_by_lines()\n",
    "    print()\n",
    "    save_file(summary, arc, str(i), version, inp)\n",
    "    i += 1\n",
    "  else:\n",
    "    print(\"No summary was generated.\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
